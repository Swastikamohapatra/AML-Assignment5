{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-23T10:51:41.065267Z","iopub.status.busy":"2024-04-23T10:51:41.064876Z","iopub.status.idle":"2024-04-23T10:51:45.419664Z","shell.execute_reply":"2024-04-23T10:51:45.418861Z","shell.execute_reply.started":"2024-04-23T10:51:41.065234Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import transformers\n","from transformers import AutoModel, BertTokenizerFast, BertTokenizer\n","from tqdm.notebook import tqdm\n","from torch.utils.data import TensorDataset\n","from transformers import BertForSequenceClassification"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:51:45.422048Z","iopub.status.busy":"2024-04-23T10:51:45.421339Z","iopub.status.idle":"2024-04-23T10:51:45.479229Z","shell.execute_reply":"2024-04-23T10:51:45.478203Z","shell.execute_reply.started":"2024-04-23T10:51:45.422020Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:51:45.492317Z","iopub.status.busy":"2024-04-23T10:51:45.491710Z","iopub.status.idle":"2024-04-23T10:51:45.631082Z","shell.execute_reply":"2024-04-23T10:51:45.630082Z","shell.execute_reply.started":"2024-04-23T10:51:45.492286Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>selected_text</th>\n","      <th>sentiment</th>\n","      <th>Time of Tweet</th>\n","      <th>Age of User</th>\n","      <th>Country</th>\n","      <th>Population -2020</th>\n","      <th>Land Area (Km²)</th>\n","      <th>Density (P/Km²)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cb774db0d1</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>neutral</td>\n","      <td>morning</td>\n","      <td>0-20</td>\n","      <td>Afghanistan</td>\n","      <td>38928346</td>\n","      <td>652860.0</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>549e992a42</td>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>Sooo SAD</td>\n","      <td>negative</td>\n","      <td>noon</td>\n","      <td>21-30</td>\n","      <td>Albania</td>\n","      <td>2877797</td>\n","      <td>27400.0</td>\n","      <td>105</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>088c60f138</td>\n","      <td>my boss is bullying me...</td>\n","      <td>bullying me</td>\n","      <td>negative</td>\n","      <td>night</td>\n","      <td>31-45</td>\n","      <td>Algeria</td>\n","      <td>43851044</td>\n","      <td>2381740.0</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9642c003ef</td>\n","      <td>what interview! leave me alone</td>\n","      <td>leave me alone</td>\n","      <td>negative</td>\n","      <td>morning</td>\n","      <td>46-60</td>\n","      <td>Andorra</td>\n","      <td>77265</td>\n","      <td>470.0</td>\n","      <td>164</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>358bd9e861</td>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>Sons of ****,</td>\n","      <td>negative</td>\n","      <td>noon</td>\n","      <td>60-70</td>\n","      <td>Angola</td>\n","      <td>32866272</td>\n","      <td>1246700.0</td>\n","      <td>26</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       textID                                               text  \\\n","0  cb774db0d1                I`d have responded, if I were going   \n","1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n","2  088c60f138                          my boss is bullying me...   \n","3  9642c003ef                     what interview! leave me alone   \n","4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n","\n","                         selected_text sentiment Time of Tweet Age of User  \\\n","0  I`d have responded, if I were going   neutral       morning        0-20   \n","1                             Sooo SAD  negative          noon       21-30   \n","2                          bullying me  negative         night       31-45   \n","3                       leave me alone  negative       morning       46-60   \n","4                        Sons of ****,  negative          noon       60-70   \n","\n","       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n","0  Afghanistan          38928346         652860.0               60  \n","1      Albania           2877797          27400.0              105  \n","2      Algeria          43851044        2381740.0               18  \n","3      Andorra             77265            470.0              164  \n","4       Angola          32866272        1246700.0               26  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('train.csv',encoding='unicode_escape')\n","df.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:51:45.633028Z","iopub.status.busy":"2024-04-23T10:51:45.632399Z","iopub.status.idle":"2024-04-23T10:51:45.666000Z","shell.execute_reply":"2024-04-23T10:51:45.665081Z","shell.execute_reply.started":"2024-04-23T10:51:45.632991Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","      <th>Time of Tweet</th>\n","      <th>Age of User</th>\n","      <th>Country</th>\n","      <th>Population -2020</th>\n","      <th>Land Area (Km²)</th>\n","      <th>Density (P/Km²)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>f87dea47db</td>\n","      <td>Last session of the day  http://twitpic.com/67ezh</td>\n","      <td>neutral</td>\n","      <td>morning</td>\n","      <td>0-20</td>\n","      <td>Afghanistan</td>\n","      <td>38928346.0</td>\n","      <td>652860.0</td>\n","      <td>60.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>96d74cb729</td>\n","      <td>Shanghai is also really exciting (precisely -...</td>\n","      <td>positive</td>\n","      <td>noon</td>\n","      <td>21-30</td>\n","      <td>Albania</td>\n","      <td>2877797.0</td>\n","      <td>27400.0</td>\n","      <td>105.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>eee518ae67</td>\n","      <td>Recession hit Veronique Branquinho, she has to...</td>\n","      <td>negative</td>\n","      <td>night</td>\n","      <td>31-45</td>\n","      <td>Algeria</td>\n","      <td>43851044.0</td>\n","      <td>2381740.0</td>\n","      <td>18.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>01082688c6</td>\n","      <td>happy bday!</td>\n","      <td>positive</td>\n","      <td>morning</td>\n","      <td>46-60</td>\n","      <td>Andorra</td>\n","      <td>77265.0</td>\n","      <td>470.0</td>\n","      <td>164.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>33987a8ee5</td>\n","      <td>http://twitpic.com/4w75p - I like it!!</td>\n","      <td>positive</td>\n","      <td>noon</td>\n","      <td>60-70</td>\n","      <td>Angola</td>\n","      <td>32866272.0</td>\n","      <td>1246700.0</td>\n","      <td>26.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       textID                                               text sentiment  \\\n","0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n","1  96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n","2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n","3  01082688c6                                        happy bday!  positive   \n","4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n","\n","  Time of Tweet Age of User      Country  Population -2020  Land Area (Km²)  \\\n","0       morning        0-20  Afghanistan        38928346.0         652860.0   \n","1          noon       21-30      Albania         2877797.0          27400.0   \n","2         night       31-45      Algeria        43851044.0        2381740.0   \n","3       morning       46-60      Andorra           77265.0            470.0   \n","4          noon       60-70       Angola        32866272.0        1246700.0   \n","\n","   Density (P/Km²)  \n","0             60.0  \n","1            105.0  \n","2             18.0  \n","3            164.0  \n","4             26.0  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df_test = pd.read_csv('test.csv',encoding='unicode_escape')\n","df_test.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:51:45.667293Z","iopub.status.busy":"2024-04-23T10:51:45.667021Z","iopub.status.idle":"2024-04-23T10:51:45.674322Z","shell.execute_reply":"2024-04-23T10:51:45.673507Z","shell.execute_reply.started":"2024-04-23T10:51:45.667269Z"},"trusted":true},"outputs":[],"source":["df['text'] = df['text'].astype(str)\n","df_test['text'] = df_test['text'].astype(str)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:51:45.675938Z","iopub.status.busy":"2024-04-23T10:51:45.675632Z","iopub.status.idle":"2024-04-23T10:51:45.708275Z","shell.execute_reply":"2024-04-23T10:51:45.707407Z","shell.execute_reply.started":"2024-04-23T10:51:45.675911Z"},"trusted":true},"outputs":[],"source":["df['label'] = df['sentiment'].apply(lambda x: 0 if x == 'negative' else (2 if x == 'neutral' else 2))\n","df_test['label'] = df_test['sentiment'].apply(lambda x: 0 if x == 'negative' else (2 if x == 'neutral' else 2))"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:51:45.709908Z","iopub.status.busy":"2024-04-23T10:51:45.709566Z","iopub.status.idle":"2024-04-23T10:51:45.733603Z","shell.execute_reply":"2024-04-23T10:51:45.732668Z","shell.execute_reply.started":"2024-04-23T10:51:45.709877Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n","                                                  df.label.values, \n","                                                  test_size=0.15, \n","                                                  random_state=42, \n","                                                  stratify=df.label.values)\n","\n","df['data_type'] = ['not_set']*df.shape[0]\n","\n","df.loc[X_train, 'data_type'] = 'train'\n","df.loc[X_val, 'data_type'] = 'val'"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:51:45.735290Z","iopub.status.busy":"2024-04-23T10:51:45.734924Z","iopub.status.idle":"2024-04-23T10:51:45.740292Z","shell.execute_reply":"2024-04-23T10:51:45.739257Z","shell.execute_reply.started":"2024-04-23T10:51:45.735256Z"},"trusted":true},"outputs":[],"source":["X_test, y_test = df_test.index.values, df_test.label.values"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:51:45.744280Z","iopub.status.busy":"2024-04-23T10:51:45.744009Z","iopub.status.idle":"2024-04-23T10:51:45.922614Z","shell.execute_reply":"2024-04-23T10:51:45.921655Z","shell.execute_reply.started":"2024-04-23T10:51:45.744257Z"},"trusted":true},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n","                                          do_lower_case=True)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:51:45.924361Z","iopub.status.busy":"2024-04-23T10:51:45.924019Z","iopub.status.idle":"2024-04-23T10:52:10.902585Z","shell.execute_reply":"2024-04-23T10:52:10.901693Z","shell.execute_reply.started":"2024-04-23T10:51:45.924330Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","C:\\Users\\arvin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}],"source":["encoded_data_train = tokenizer.batch_encode_plus(\n","    df[df.data_type=='train'].text.values, \n","    add_special_tokens=True, \n","    return_attention_mask=True, \n","    pad_to_max_length=True, \n","    max_length=256, \n","    return_tensors='pt'\n",")\n","\n","encoded_data_val = tokenizer.batch_encode_plus(\n","    df[df.data_type=='val'].text.values, \n","    add_special_tokens=True, \n","    return_attention_mask=True, \n","    pad_to_max_length=True, \n","    max_length=256, \n","    return_tensors='pt'\n",")\n","\n","encoded_data_test = tokenizer.batch_encode_plus(\n","    df_test.text.values, \n","    add_special_tokens=True, \n","    return_attention_mask=True, \n","    pad_to_max_length=True, \n","    max_length=256, \n","    return_tensors='pt'\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:52:10.906014Z","iopub.status.busy":"2024-04-23T10:52:10.905267Z","iopub.status.idle":"2024-04-23T10:52:10.928324Z","shell.execute_reply":"2024-04-23T10:52:10.927643Z","shell.execute_reply.started":"2024-04-23T10:52:10.905984Z"},"trusted":true},"outputs":[],"source":["input_ids_train = encoded_data_train['input_ids']\n","attention_masks_train = encoded_data_train['attention_mask']\n","labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n","\n","input_ids_val = encoded_data_val['input_ids']\n","attention_masks_val = encoded_data_val['attention_mask']\n","labels_val = torch.tensor(df[df.data_type=='val'].label.values)\n","\n","input_ids_test = encoded_data_test['input_ids']\n","attention_masks_test = encoded_data_test['attention_mask']\n","labels_test = torch.tensor(df_test.label.values)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:52:10.929616Z","iopub.status.busy":"2024-04-23T10:52:10.929318Z","iopub.status.idle":"2024-04-23T10:52:10.934259Z","shell.execute_reply":"2024-04-23T10:52:10.933334Z","shell.execute_reply.started":"2024-04-23T10:52:10.929589Z"},"trusted":true},"outputs":[],"source":["dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n","dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n","dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:52:10.935648Z","iopub.status.busy":"2024-04-23T10:52:10.935321Z","iopub.status.idle":"2024-04-23T10:52:11.555009Z","shell.execute_reply":"2024-04-23T10:52:11.554036Z","shell.execute_reply.started":"2024-04-23T10:52:10.935614Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",")"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n","                                                      num_labels=3,\n","                                                      output_attentions=False,\n","                                                      output_hidden_states=False)\n","model.to(device)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:52:11.556502Z","iopub.status.busy":"2024-04-23T10:52:11.556185Z","iopub.status.idle":"2024-04-23T10:52:11.561990Z","shell.execute_reply":"2024-04-23T10:52:11.561049Z","shell.execute_reply.started":"2024-04-23T10:52:11.556466Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","batch_size = 3\n","\n","dataloader_train = DataLoader(dataset_train, \n","                              sampler=RandomSampler(dataset_train), \n","                              batch_size=batch_size)\n","\n","dataloader_validation = DataLoader(dataset_val, \n","                                   sampler=SequentialSampler(dataset_val), \n","                                   batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:52:11.563598Z","iopub.status.busy":"2024-04-23T10:52:11.563215Z","iopub.status.idle":"2024-04-23T10:52:11.583255Z","shell.execute_reply":"2024-04-23T10:52:11.582394Z","shell.execute_reply.started":"2024-04-23T10:52:11.563560Z"},"trusted":true},"outputs":[],"source":["from transformers import AdamW, get_linear_schedule_with_warmup\n","\n","optimizer = AdamW(model.parameters(),\n","                  lr=1e-5, \n","                  eps=1e-8)\n","                  \n","epochs = 5\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps=0,\n","                                            num_training_steps=len(dataloader_train)*epochs)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:52:11.584678Z","iopub.status.busy":"2024-04-23T10:52:11.584337Z","iopub.status.idle":"2024-04-23T10:52:11.591551Z","shell.execute_reply":"2024-04-23T10:52:11.590669Z","shell.execute_reply.started":"2024-04-23T10:52:11.584654Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import f1_score\n","\n","def f1_score_func(preds, labels):\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return f1_score(labels_flat, preds_flat, average='weighted')"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:52:11.592930Z","iopub.status.busy":"2024-04-23T10:52:11.592661Z","iopub.status.idle":"2024-04-23T11:12:38.502090Z","shell.execute_reply":"2024-04-23T11:12:38.500608Z","shell.execute_reply.started":"2024-04-23T10:52:11.592904Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e2bd7e8a2d6048a8973adc2dd386ca8b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2989c4ca94574a8eb9a60c79830f8534","version_major":2,"version_minor":0},"text/plain":["Epoch 1:   0%|          | 0/7786 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1\n","Training loss: 0.49510224615010195\n","Validation loss: 0.504013134223663\n","F1 Score (Weighted): 0.8828528448099323\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"718c0c3a15c143dd80798ab2f74f3e55","version_major":2,"version_minor":0},"text/plain":["Epoch 2:   0%|          | 0/7786 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Epoch 2\n","Training loss: 0.35390886995832765\n","Validation loss: 0.5526911089309194\n","F1 Score (Weighted): 0.8825986848357465\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"691bf928c9014ea2aab0f0b990ff69fc","version_major":2,"version_minor":0},"text/plain":["Epoch 3:   0%|          | 0/7786 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Epoch 3\n","Training loss: 0.21275650961481418\n","Validation loss: 0.7557979568770388\n","F1 Score (Weighted): 0.8802630920005244\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cecfe4f6b5404d86bb0662c33555de52","version_major":2,"version_minor":0},"text/plain":["Epoch 4:   0%|          | 0/7786 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Epoch 4\n","Training loss: 0.11103429650725201\n","Validation loss: 0.8676929302087149\n","F1 Score (Weighted): 0.874556882979172\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a9221b309af4c03a1196db04f4b4390","version_major":2,"version_minor":0},"text/plain":["Epoch 5:   0%|          | 0/7786 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Epoch 5\n","Training loss: 0.052364940349146565\n","Validation loss: 0.983113909100312\n","F1 Score (Weighted): 0.8751715952387781\n"]}],"source":["import random\n","\n","seed_val = 17\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","def evaluate(dataloader_val):\n","\n","    model.eval()\n","    \n","    loss_val_total = 0\n","    predictions, true_vals = [], []\n","    \n","    for batch in dataloader_val:\n","        \n","        batch = tuple(b.to(device) for b in batch)\n","        \n","        inputs = {'input_ids':      batch[0],\n","                  'attention_mask': batch[1],\n","                  'labels':         batch[2],\n","                 }\n","\n","        with torch.no_grad():        \n","            outputs = model(**inputs)\n","            \n","        loss = outputs[0]\n","        logits = outputs[1]\n","        loss_val_total += loss.item()\n","\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = inputs['labels'].cpu().numpy()\n","        predictions.append(logits)\n","        true_vals.append(label_ids)\n","    \n","    loss_val_avg = loss_val_total/len(dataloader_val) \n","    \n","    predictions = np.concatenate(predictions, axis=0)\n","    true_vals = np.concatenate(true_vals, axis=0)\n","            \n","    return loss_val_avg, predictions, true_vals\n","    \n","for epoch in tqdm(range(1, epochs+1)):\n","    \n","    model.train()\n","    \n","    loss_train_total = 0\n","\n","    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n","    for batch in progress_bar:\n","\n","        model.zero_grad()\n","        \n","        batch = tuple(b.to(device) for b in batch)\n","        \n","        inputs = {'input_ids':      batch[0],\n","                  'attention_mask': batch[1],\n","                  'labels':         batch[2],\n","                 }       \n","\n","        outputs = model(**inputs)\n","        \n","        loss = outputs[0]\n","        loss_train_total += loss.item()\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        optimizer.step()\n","        scheduler.step()\n","        \n","        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n","         \n","        \n","    torch.save(model.state_dict(), r\"E:\\VSCode\\Applied-ML\\Assignment-5-Swastika\\finetuned_BERT_epoch_{epoch}.model\")\n","    \n","        \n","    tqdm.write(f'\\nEpoch {epoch}')\n","    \n","    loss_train_avg = loss_train_total/len(dataloader_train)            \n","    tqdm.write(f'Training loss: {loss_train_avg}')\n","    \n","    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n","    val_f1 = f1_score_func(predictions, true_vals)\n","    tqdm.write(f'Validation loss: {val_loss}')\n","    tqdm.write(f'F1 Score (Weighted): {val_f1}')"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",")"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n","                                                      num_labels=3,\n","                                                      output_attentions=False,\n","                                                      output_hidden_states=False)\n","\n","model.to(device)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# Using the best model\n","\n","model.load_state_dict(torch.load('data_volume/finetuned_BERT_epoch_1.model', map_location=torch.device('cpu')))"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["dataloader_test = DataLoader(dataset_test, \n","                                   sampler=SequentialSampler(dataset_test), \n","                                   batch_size=batch_size)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["_, predictions, true_vals = evaluate(dataloader_test)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["label_dict = {'negative':0, 'neutral':2, 'positive':4}"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["def accuracy_per_class(preds, labels):\n","    label_dict_inverse = {v: k for k, v in label_dict.items()}\n","    \n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    for label in np.unique(labels_flat):\n","        y_preds = preds_flat[labels_flat==label]\n","        y_true = labels_flat[labels_flat==label]\n","        print(f'Class: {label_dict_inverse[label]}')\n","        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Class: negative\n","Accuracy: 792/1001\n","\n","Class: neutral\n","Accuracy: 3564/3814\n","\n"]}],"source":["accuracy_per_class(predictions, true_vals)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4860787,"sourceId":8204206,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
